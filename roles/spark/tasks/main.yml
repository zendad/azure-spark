---
- name: Install java yum
  become: yes
  yum:
    name: java-1.8.0-openjdk
    state: present
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'


- name: Install java apt
  become: yes
  apt:
    name: openjdk-8-jdk
    state: present
  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'

- name: Create spark user group
  become: yes
  group:
    name: spark
    state: present

- name: Create spark user
  become: yes
  user:
    name: spark
    group: spark
    state: present

- name: Install scala rpm sys
  become: yes
  yum:
    name: "{{ scala_release_url }}/scala/{{ scala_version }}/scala-{{ scala_version }}.rpm"
    state: present
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'

- name: Install scala debian
  become: yes
  apt:
    name: scala
    state: present
  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'

- name: Create spark directory
  become: yes
  file:
    path: /opt/spark
    state: directory
    owner: spark
    group: spark
    mode: 0755

- name: Download Spark binaries
  get_url:
    url: "{{ spark_release_url }}/spark-{{ spark_version }}/spark-{{ spark_version }}-bin-hadoop2.7.tgz"
    dest: /tmp
  
- name: Unpack Spark binaries
  become: yes
  unarchive:
    creates: "/opt/spark/spark-{{ spark_version }}-bin-hadoop2.7/bin/spark-submit"
    remote_src: yes
    src: "/tmp/spark-{{ spark_version }}-bin-hadoop2.7.tgz"
    dest: /opt/spark
    owner: spark
    group: spark

- name: Symlink current spark
  become: yes
  file:
    path: /opt/spark/current
    src: "/opt/spark/spark-{{ spark_version }}-bin-hadoop2.7"
    state: link
    owner: spark
    group: spark
    mode: 0755

- name: Configure Spark
  become: yes 
  template:
    src: "templates/{{ item.name }}.j2"
    dest: "/opt/spark/current/conf/{{ item.name }}"
    owner: spark
    group: spark 
    mode: "{{ item.mode }}"
  with_items:
    - { name: "spark-defaults.conf", mode: "0644" }
    - { name: "spark-env.sh", mode: "0755" }      

- name: Add Spark bin directory to PATH
  become: yes
  template: 
    src: "templates/spark.sh.j2"
    dest: "/etc/profile.d/spark.sh"
    mode: 0644
